{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import abc\n",
    "import collections.abc\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import Generator, List, Optional, Tuple, Type\n",
    "\n",
    "from pydantic import BaseModel, FilePath, validator\n",
    "\n",
    "from decord import VideoReader, cpu\n",
    "from decord._ffi.ndarray import DECORDContext\n",
    "\n",
    "from ffmpeg_tqdm_wrapper import analyze_stream, ffmpeg_to_tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "root.addHandler(handler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "random.seed(\"16-896-375\")  # my student number"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_filename_without_extension(path: Path) -> str:\n",
    "    filename = os.path.basename(path)\n",
    "    return \"\".join(filename.split('.')[:-1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class FrameSelectionStrategyEnum(str, Enum):\n",
    "    naive = 'naive'\n",
    "    segment_random = 'segment_random'\n",
    "\n",
    "\n",
    "class VideoProcessParameters(BaseModel):\n",
    "    input: FilePath\n",
    "    output_folder: Path\n",
    "    frames_skip: int\n",
    "\n",
    "    @classmethod\n",
    "    @validator('output_folder')\n",
    "    def output_folder_must_exist_and_be_a_folder(cls, v: Path) -> Path:\n",
    "        assert v.exists() and os.path.isdir(v)\n",
    "        return v\n",
    "\n",
    "    @property\n",
    "    def file_wo_ext(self) -> str:\n",
    "        return get_filename_without_extension(self.input)\n",
    "\n",
    "    def get_output_path_with_filename(self, filename: str) -> Path:\n",
    "        return self.output_folder / filename"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# This cell is tagged `parameters` to accept arguments from papermill cli\n",
    "input: Optional[str] = '../SZTR/video/SZTRA201a08.mov'  # input video file\n",
    "i: Optional[str] = None  # input video file, can be used instead of parameter input (input has precedence)\n",
    "output: Optional[str] = '../SZTR/video/'  # output folder\n",
    "o: Optional[str] = None  # output folder, can be used instead of parameter output (output has precedence)\n",
    "frames_skip: int = 12  # as the videos are 25 fps (get 2 frames per second by default)\n",
    "\n",
    "_extract_frames_2_images: bool = False\n",
    "_demo: bool = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "VideoProcessParameters(input=PosixPath('../SZTR/video/SZTRA201a08.mov'), output_folder=PosixPath('../SZTR/video'), frames_skip=12)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile parameters with pydantic validation\n",
    "parameters = VideoProcessParameters(input=input or i, output_folder=output or o, frames_skip=frames_skip)\n",
    "parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Adapted from CLIP4Clip: https://github.com/ArrowLuo/CLIP4Clip/blob/master/preprocess/compress_video.py\n",
    "# but don't change the frame rate as be which to have different frame selection strategies\n",
    "# and use ffmpeg_to_tqdm helper\n",
    "def scale_compress_video(input_video_path: Path, output_video_path: Path) -> int:\n",
    "    logger = logging.getLogger(f'ffmpeg-{str(output_video_path)}')\n",
    "    logger.debug(\"Using ffmpeg to scale and compress an original video.\")\n",
    "\n",
    "    stream_info = analyze_stream(logger, str(input_video_path))\n",
    "\n",
    "    command = ['ffmpeg',\n",
    "                '-y',  # (optional) overwrite output file if it exists\n",
    "                '-i', str(input_video_path),\n",
    "                '-filter:v',\n",
    "                \"scale='if(gt(a,1),trunc(oh*a/2)*2,224)':'if(gt(a,1),224,trunc(ow*a/2)*2)'\",  # scale to 224\n",
    "                '-map', '0:v',\n",
    "                '-vcodec', 'libx264',    # additionally, change the codec for better\n",
    "                                        # compression\n",
    "                                        # display codecs with: `ffmpeg -codecs`\n",
    "            #    '-r', '3',  # frames per second\n",
    "                str(output_video_path),\n",
    "                ]\n",
    "    # to avoid carriage return ('\\r') in ffmpeg output, to mess with the reading of the\n",
    "    # progress, use 'universal_newlines' argument\n",
    "    # https://github.com/chriskiehl/Gooey/issues/495#issuecomment-614991802\n",
    "    ffmpeg_process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "\n",
    "    return ffmpeg_to_tqdm(logger, ffmpeg_process, duration=stream_info.get('duration'), tqdm_desc=\"FFMPEG scale down to 224 and encode libx264\").returncode"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FFMPEG scale down to 224 and encode libx264: 268.0segment [00:09, 29.56segment/s]                      \n"
     ]
    }
   ],
   "source": [
    "scaled_down_video_path = parameters.get_output_path_with_filename(f\"{parameters.file_wo_ext}_224.mp4\")\n",
    "scale_compress_video(parameters.input, scaled_down_video_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class FrameSelectionStrategy(collections.abc.Iterator):\n",
    "\n",
    "    total_images_files_size: int  # index in the sequence of frames to select\n",
    "\n",
    "    def __init__(self, interval: int, frames_count: int):\n",
    "        self.interval = interval\n",
    "        self.frames_count = frames_count\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def frames_i_sequence(self) -> List[int]:\n",
    "        \"\"\"Returns the indexes to extract from the sequence between [0; frames_count] inclusive\"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "    @property\n",
    "    @abc.abstractmethod\n",
    "    def size(self) -> int:\n",
    "        \"\"\"Returns the number of frames to extract (size of frame_i_sequence)\"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "    def __iter__(self) -> \"FrameSelectionStrategy\":\n",
    "        self.i = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> int:\n",
    "        if self.i >= self.size:\n",
    "            raise StopIteration\n",
    "\n",
    "        i = self.i\n",
    "        self.i += 1\n",
    "        return self.frames_i_sequence[i]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.size\n",
    "\n",
    "\n",
    "class FrameExtractor(collections.abc.Iterator):\n",
    "    \"\"\"Example:\n",
    "\n",
    "    ```python\n",
    "    >>> for frame, idx in FrameExtractor(Path(\"../SZTR/video/SZTRA201a08_224.mp4\"), RandomSequenceFrameSelectionStrategy, 12):\n",
    "    >>>     print(PIL.Image.fromarray(frame))\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    strategy: FrameSelectionStrategy = None\n",
    "\n",
    "    def __init__(self, video_path: Path, strategy_type: Type[FrameSelectionStrategy], interval: int, video_reader_context: DECORDContext = cpu(0)):\n",
    "        self.vr = VideoReader(str(video_path), video_reader_context)\n",
    "        self.strategy = strategy_type(interval, len(self.vr))\n",
    "\n",
    "    @property\n",
    "    def frames_to_extract(self) -> int:\n",
    "        if not hasattr(self, \"strategy_iterator\"):\n",
    "            iter(self)\n",
    "        return len(self.strategy_iterator)\n",
    "\n",
    "    @property\n",
    "    def total_frames(self) -> int:\n",
    "        return len(self.vr)\n",
    "\n",
    "    def __iter__(self) -> \"FrameExtractor\":\n",
    "        self.strategy_iterator = iter(self.strategy)\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Tuple[np.ndarray, int]:\n",
    "        # delegate StopIteration to the strategy\n",
    "        next_frame_i = next(self.strategy_iterator)\n",
    "        vr_frame_array = self.vr[next_frame_i]\n",
    "        return vr_frame_array.asnumpy(), next_frame_i\n",
    "\n",
    "\n",
    "class TrivialFrameSelectionStrategy(FrameSelectionStrategy):\n",
    "    \"\"\"Select a frame every N frames (N := interval) and will always include the last frame\n",
    "    (frames_count - 1)\"\"\"\n",
    "\n",
    "    def __init__(self, interval: int, frames_count: int):\n",
    "        super().__init__(interval, frames_count)\n",
    "        self._frame_i_sequence = list(range(0, frames_count, interval)) + (\n",
    "            [] if (frames_count - 1) % interval == 0 else [frames_count - 1]\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def frames_i_sequence(self) -> List[int]:\n",
    "        return self._frame_i_sequence\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        return len(self._frame_i_sequence)\n",
    "\n",
    "\n",
    "class RandomSequenceFrameSelectionStrategy(TrivialFrameSelectionStrategy):\n",
    "    \"\"\"In every sequence of N frames, select randomly a frame.\n",
    "    Example:\n",
    "       [0     [12    [24    [36    [48    [60  ...\n",
    "        +------+------+------+------+------+----\n",
    "        |   7  |  22  |  29  |  38  |  53  |\n",
    "        +------+------+------+------+------+----\n",
    "\n",
    "    >>> [random.randrange(total_images_files_size, total_images_files_size + 12) for i in range(0, 60, 12)]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, interval: int, frames_count: int):\n",
    "        super().__init__(interval, frames_count)\n",
    "        self._frame_i_sequence = [random.randint(start, end) for start, end in zip(super().frames_i_sequence[:-1], super().frames_i_sequence[1:])]\n",
    "\n",
    "    @property\n",
    "    def frames_i_sequence(self) -> List[int]:\n",
    "        return self._frame_i_sequence\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        return len(self._frame_i_sequence)\n",
    "\n",
    "\n",
    "class UnionFrameSelectionStrategy(FrameSelectionStrategy):\n",
    "\n",
    "    def __init__(self, strategy_types: List[Type[FrameSelectionStrategy]], interval: int, frames_count: int):\n",
    "        super().__init__(interval, frames_count)\n",
    "        self.strategies = [strategy(interval, frames_count) for strategy in strategy_types]\n",
    "        # sorted(set(TrivialFrameSelectionStrategy(12, 3373)) | set(RandomSequenceFrameSelectionStrategy(12, 3373)))\n",
    "        self._frame_i_sequence = sorted({frame for strategy in self.strategies for frame in strategy})\n",
    "\n",
    "    @property\n",
    "    def frames_i_sequence(self) -> List[int]:\n",
    "        return self._frame_i_sequence\n",
    "\n",
    "    @property\n",
    "    def size(self) -> int:\n",
    "        return len(self._frame_i_sequence)\n",
    "\n",
    "    def get_selection_strategy_by_frame(self) -> Generator[Tuple[str, int], None, None]:\n",
    "        for strategy_name, frames_i_sequence in [(type(strategy).__name__, strategy.frames_i_sequence) for strategy in self.strategies]:\n",
    "            for frame_i in frames_i_sequence:\n",
    "                yield strategy_name, frame_i\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "if _demo:\n",
    "    frames = list(TrivialFrameSelectionStrategy(parameters.frames_skip, 3373))\n",
    "    frames[-10:], len(frames)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "if _demo:\n",
    "    list(RandomSequenceFrameSelectionStrategy(parameters.frames_skip, 3373))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "if _demo:\n",
    "    assert len(TrivialFrameSelectionStrategy(parameters.frames_skip, 3373)) == len(RandomSequenceFrameSelectionStrategy(parameters.frames_skip, 3373)) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "UnionFrameSelectionStrategyCtor = partial(UnionFrameSelectionStrategy, [TrivialFrameSelectionStrategy, RandomSequenceFrameSelectionStrategy])\n",
    "frame_selection = FrameExtractor(scaled_down_video_path, UnionFrameSelectionStrategyCtor, parameters.frames_skip)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames in sequences: 3373\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of frames in sequences: {len(frame_selection.vr)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "if _demo:\n",
    "    PIL.Image.fromarray(frame_selection.vr[0].asnumpy())  # first frame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "if _demo:\n",
    "    PIL.Image.fromarray(frame_selection.vr[12*25].asnumpy())  # frame with a person rolling on the floor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def extract_frames_and_save_by_unit(frame_selection: FrameExtractor, output_folder: Path, filename_prefix: str) -> Generator[Path, None, None]:\n",
    "    digits = len(str(frame_selection.total_frames))\n",
    "\n",
    "    for img, idx in tqdm(frame_selection, total=frame_selection.frames_to_extract, desc=\"Extracting frames and saving images\"):\n",
    "        img_output_path = output_folder / f\"{filename_prefix}_{idx:0{digits}}.png\"\n",
    "        PIL.Image.fromarray(img).save(img_output_path)\n",
    "        yield img_output_path\n",
    "\n",
    "if _extract_frames_2_images:\n",
    "    produced_image_paths = list(extract_frames_and_save_by_unit(frame_selection, parameters.output_folder, f\"{parameters.file_wo_ext}_224\"))\n",
    "    print(list(frame_selection.strategy.get_selection_strategy_by_frame()))\n",
    "else:\n",
    "    produced_image_paths = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compare File System Space Usage\n",
    "Quickly checking into the fs, we can see that the series of images use more disk space than the video, due to the compression of the video encoder most likely."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "if _extract_frames_2_images:\n",
    "    images_file_sizes = [(path, os.path.getsize(path)) for path in produced_image_paths]\n",
    "    video_size = os.path.getsize(parameters.output_video_path)\n",
    "\n",
    "    print(\"# First 10 extracted images sizes in bytes\")\n",
    "    print(images_file_sizes[:10])\n",
    "    print(\"...\")\n",
    "\n",
    "    print()\n",
    "    print(f\"# Video size: {video_size} bytes\")\n",
    "\n",
    "    total_images_files_size = sum([size for _path, size in images_file_sizes])\n",
    "    print(total_images_files_size, \"vs\", video_size, f\"({video_size - total_images_files_size} bytes)\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract the frames but keep them in a video file using FFMPEG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Using Stackoverflow answer, we can select multiple frames with the '+' \"operation\" inside the select\n",
    "def get_ffmpeg_select_argument(frames_sequence: List[int], setpts_filter: float) -> str:\n",
    "    \"\"\"Produce a string to be used with the FFMPEG command and its \"select\" argument.\n",
    "\n",
    "    :param frames_sequence: linear or not list of frames to extract.\n",
    "                            Example: 0, 12, 24, 36, 48, 60, ...\n",
    "                            or:      6, 23, 27, 42, 50, 68, ...\n",
    "    :param setpts_filter: from FFMPEG manual page:\n",
    "                            \"setpts\" filter, which only sets timestamps and otherwise passes the frames unchanged\n",
    "                          It is expected to be smaller than 1 in can less frames are selected and it is wished to\n",
    "                          speed up the video.\n",
    "                          Usually, it is expected to get 1/FRAMES_SKIP\n",
    "                          Example: *0.25* (for a FRAMES_SKIP of 4)\n",
    "    :return: string to be used to run the FFMPEG command for the \"select\" argument like: ffmpeg -i SZTRA201a08_224.mp4 -vf select='eq(n\\,0)+eq(n\\,12)+eq(n\\,24)+eq(n\\,36)+eq(n\\,48)+eq(n\\,60), setpts=0.08333333333*PTS' -an SZTRA201a08_224_12_random.mp4\n",
    "    \"\"\"\n",
    "    # eq(n\\\\,0)+eq(n\\\\,12)+eq(n\\\\,24)+eq(n\\\\,36)+eq(n\\\\,48)\n",
    "    eq_chain = \"+\".join([f\"eq(n\\,{n})\" for n in frames_sequence])\n",
    "    setpts = f\"setpts={setpts_filter}*PTS\"\n",
    "\n",
    "    return f\"'{eq_chain}',{setpts}\"\n",
    "\n",
    "\n",
    "if _demo:\n",
    "    get_ffmpeg_select_argument(\n",
    "        list(TrivialFrameSelectionStrategy(parameters.frames_skip, frames_count=frame_selection.total_frames)),\n",
    "        1 / parameters.frames_skip\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FFMPEG execution: 145.0segment [00:00, 298.86segment/s]           \n",
      "FFMPEG execution: 145.0segment [00:00, 347.84segment/s]           \n"
     ]
    }
   ],
   "source": [
    "def extract_frames_in_video(frames_sequence: List[int], setpts_filter: float, input_video_path: Path, output_video_path: Path) -> int:\n",
    "    logger = logging.getLogger(f'ffmpeg-{str(output_video_path)}')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.debug(\"Using ffmpeg to extract frames from a video.\")\n",
    "\n",
    "    stream_info = analyze_stream(logger, str(input_video_path))\n",
    "\n",
    "    command = ['ffmpeg',\n",
    "                '-y',  # (optional) overwrite output file if it exists\n",
    "                '-i', str(input_video_path),\n",
    "                '-vf',\n",
    "                f\"select={get_ffmpeg_select_argument(frames_sequence, setpts_filter)}\",\n",
    "                '-an',\n",
    "                str(output_video_path),\n",
    "                ]\n",
    "\n",
    "    # to avoid carriage return ('\\r') in ffmpeg output, to mess with the reading of the\n",
    "    # progress, use 'universal_newlines' argument\n",
    "    # https://github.com/chriskiehl/Gooey/issues/495#issuecomment-614991802\n",
    "    ffmpeg_process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "    return ffmpeg_to_tqdm(logger, ffmpeg_process, duration=stream_info.get('duration'), tqdm_desc=\"FFMPEG select subset of frames\").returncode\n",
    "\n",
    "\n",
    "extract_frames_in_video(\n",
    "    list(TrivialFrameSelectionStrategy(parameters.frames_skip, frames_count=frame_selection.total_frames)),\n",
    "    1 / parameters.frames_skip, scaled_down_video_path, parameters.get_output_path_with_filename(f\"{parameters.file_wo_ext}_224_trivial_12.mp4\"))\n",
    "\n",
    "extract_frames_in_video(\n",
    "    list(RandomSequenceFrameSelectionStrategy(parameters.frames_skip, frames_count=frame_selection.total_frames)),\n",
    "    1 / parameters.frames_skip, scaled_down_video_path, parameters.get_output_path_with_filename(f\"{parameters.file_wo_ext}_224_random_sequence_12.mp4\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "16d16579ac16af49d8151a36f2799f423cff0ad66d4c2584ff74047bfbf540a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}